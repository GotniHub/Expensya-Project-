import streamlit as st
import pandas as pd
import zipfile
import os
import shutil
import re
import requests
from io import BytesIO

# =============================
#        CONFIG DE BASE
# =============================
st.set_page_config(page_title="Gestion des Missions", layout="wide")
# si ta version de Streamlit supporte st.logo, garde la ligne ci-dessous
try:
    st.logo("LOGO.png", icon_image="Logom.png")
except Exception:
    pass
try:
    from streamlit_plotly_events import plotly_events
    PLOTLY_EVENTS_AVAILABLE = True
except Exception:
    PLOTLY_EVENTS_AVAILABLE = False

st.title("üìÇ G√©n√©rateur et acc√®s aux dossiers missions")

# =============================
#    V√âRIF AUTH & MISSIONS
# =============================
if "auth_user" not in st.session_state or st.session_state["auth_user"] is None:
    st.warning("‚ö†Ô∏è Aucun utilisateur connect√©. Veuillez d‚Äôabord vous connecter depuis la page **Home**.")
    st.stop()

user = st.session_state["auth_user"]
missions = st.session_state.get("missions", [])

# Choix mission
if len(missions) == 1:
    missions_selected = missions[:]  # liste avec une seule mission
    st.info(f"‚úÖ Mission assign√©e automatiquement : {missions[0]}")
else:
    missions_selected = st.multiselect(
        "üìå S√©lectionnez vos missions :", missions, default=missions
    )
    if missions_selected:
        st.success(f"Missions s√©lectionn√©es : {', '.join(missions_selected)}")
    else:
        st.warning("‚ö†Ô∏è Aucune mission s√©lectionn√©e, merci d'en choisir au moins une.")
        st.stop()

# Bloc utilisateur (carte lat√©rale)
card_html = f"""
<div style="
    background: linear-gradient(135deg, rgba(30,45,80,0.75), rgba(46,134,193,0.75)); 
    color: white; 
    padding: 1.2rem; 
    border-radius: 12px;
    text-align: center;
    margin-bottom: 1.5rem;
    box-shadow: 0 6px 15px rgba(0,0,0,0.25);
    transform: perspective(1000px) rotateX(2deg) rotateY(-1deg);
">
    <h4 style="margin: 0; font-size: 1.2rem; font-weight: bold;">üë§ {user}</h4>
    <p style="margin: 0; font-size: 0.9rem; opacity: 0.95;">‚úîÔ∏è  Connect√© avec succ√®s</p>
</div>
"""
st.sidebar.markdown(card_html, unsafe_allow_html=True)

if st.sidebar.button("üö™ D√©connexion"):
    st.session_state["auth_user"] = None
    st.switch_page("home.py")

# =============================
#     LIEN ONEDRIVE (EXEMPLE)
# =============================
# Exctraction S1 2025 (actuel) :
# ONEDRIVE_URL = "https://adventplus-my.sharepoint.com/:u:/g/personal/igotni_adv-sud_fr/Ef8LL-Y_mNhOlCQlKHlQs1wBXzoorlA-dVNmoZ07zj3oNw?download=1"
# Exctraction S2 2024 :
ONEDRIVE_URL = "https://adventplus-my.sharepoint.com/:u:/g/personal/igotni_adv-sud_fr/EahoQ8gXXhJLpKJy4FtfyvsBsKc7r60cII0KbVjkorzH6g?download=1"
# =============================
#         UTILITAIRES
# =============================
def nettoyer_nom(nom: str) -> str:
    """Nettoie les noms de dossiers/fichiers pour compatibilit√© cross-OS."""
    return re.sub(r'[<>:"/\\|?*]', "_", str(nom).strip()).lower()

def lire_matrice(path: str) -> pd.DataFrame:
    """Essaye plusieurs noms d‚Äôonglets possibles pour la matrice."""
    xl = pd.ExcelFile(path)
    for sheet in xl.sheet_names:
        if "matrice" in sheet.lower():
            return xl.parse(sheet)
    # fallback : premier onglet
    return xl.parse(xl.sheet_names[0])

def lire_rapport(path: str) -> pd.DataFrame:
    """Lit l‚Äôonglet Rapport (ou tente un fallback)."""
    xl = pd.ExcelFile(path)
    if "Rapport" in xl.sheet_names:
        return xl.parse("Rapport")
    return xl.parse(xl.sheet_names[0])
from collections import defaultdict
def build_receipts_index_from_zipfile(zip_path: str) -> dict[str, list[tuple[str, bytes]]]:
    idx = defaultdict(list)
    with zipfile.ZipFile(zip_path, "r") as z:
        for name in z.namelist():
            if name.endswith("/"):      # ignorer les dossiers
                continue
            base = os.path.basename(name)
            if not base:
                continue
            m = re.match(r"^(\d+)", base)   # r√©f = chiffres au d√©but du nom
            if not m:
                continue
            ref = m.group(1)
            try:
                data = z.read(name)        # bytes du fichier
            except Exception:
                continue
            idx[ref].append((base, data))
    return idx
# =============================
#        TRAITEMENT ZIP
# =============================
st.divider()
if st.button("üöÄ Lancer le traitement"):
    try:
        st.info("‚è≥ T√©l√©chargement du ZIP depuis la base‚Ä¶")
        progress_bar = st.progress(0)
        status_text = st.empty()

        # √âtape 1 : t√©l√©chargement
        response = requests.get(ONEDRIVE_URL, stream=True, timeout=300)
        if response.status_code != 200:
            st.error("‚ùå Erreur lors du t√©l√©chargement OneDrive")
            st.stop()

        total_size = int(response.headers.get('content-length', 0)) or None
        downloaded_size = 0
        zip_content = BytesIO()

        for chunk in response.iter_content(chunk_size=8192):
            if chunk:
                zip_content.write(chunk)
                if total_size:
                    downloaded_size += len(chunk)
                    progress = int(downloaded_size / total_size * 100)
                    progress_bar.progress(min(progress, 100))
                    status_text.text(f"T√©l√©chargement... {progress}%")

        progress_bar.progress(100)
        status_text.text("‚úÖ T√©l√©chargement termin√©. Traitement en cours...")

        # Remettre le curseur au d√©but
        zip_content.seek(0)

        # Dossier temporaire propre
        temp_dir = "temp_result"
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        os.makedirs(temp_dir, exist_ok=True)

        # Sauvegarde du ZIP principal
        outer_zip_path = os.path.join(temp_dir, "expensya_docs.zip")
        with open(outer_zip_path, "wb") as f:
            f.write(zip_content.getvalue())

        # Extraction du ZIP principal
        with zipfile.ZipFile(outer_zip_path, "r") as outer_zip:
            outer_zip.extractall(temp_dir)

        # Identifier les fichiers (rapport, matrice, zip interne)
        rapport_file, mapping_file, inner_zip_path = None, None, None
        xlsx_files, zip_files = [], []

        for file in os.listdir(temp_dir):
            p = os.path.join(temp_dir, file)
            if os.path.isdir(p):
                continue
            if file.lower().endswith(".xlsx"):
                xlsx_files.append(p)
            elif file.lower().endswith(".zip"):
                zip_files.append(p)

        # D√©tection rapport / matrice
        for p in xlsx_files:
            fname = os.path.basename(p).lower()
            if "matrice" in fname:
                mapping_file = p
            else:
                rapport_file = p

        # S√©lection du ZIP interne (justificatifs)
        zip_candidates = [p for p in zip_files if os.path.abspath(p) != os.path.abspath(outer_zip_path)]
        if zip_candidates:
            inner_zip_path = max(zip_candidates, key=os.path.getsize)

        # V√©rifications
        if not rapport_file or not mapping_file or not inner_zip_path:
            st.error("‚ùå Impossible de trouver Rapport, Matrice ou le ZIP interne (justificatifs).")
            st.write("DEBUG ‚Äì xlsx:", [os.path.basename(p) for p in xlsx_files])
            st.write("DEBUG ‚Äì zip:", [os.path.basename(p) for p in zip_files])
            st.stop()
        # Build receipts index directly from the inner ZIP (handles subfolders)
        st.session_state["receipts_index"] = build_receipts_index_from_zipfile(inner_zip_path)
        st.success(f"üîç Index justificatifs construit pour {len(st.session_state['receipts_index'])} r√©f√©rences.")
        st.info(f"üìÑ Total fichiers justificatifs: {sum(len(v) for v in st.session_state['receipts_index'].values())}")
        # Lecture des donn√©es
        df = lire_rapport(rapport_file)
        df_map = lire_matrice(mapping_file)

        # Colonnes minimales
        needed = {"Client (R√©f√©rence)", "Utilisateur", "R√©f√©rence"}
        if not needed.issubset(df.columns):
            st.error(f"Colonnes manquantes dans le Rapport : {sorted(list(needed - set(df.columns)))}")
            st.stop()

        # Merge mapping (si dispo)
        if {"Client (R√©f√©rence)", "Modification Code Expensya"}.issubset(df_map.columns):
            df = df.merge(
                df_map[["Client (R√©f√©rence)", "Modification Code Expensya"]],
                on="Client (R√©f√©rence)",
                how="left"
            )

        # Retirer un √©ventuel "Grand Totale" final
        if not df.empty:
            last_row = df.tail(1).astype(str).apply(lambda x: x.str.contains("Grand Totale", case=False).any(), axis=1).iloc[0]
            if last_row:
                df = df.iloc[:-1]

        # Mission finale / nettoy√©e
        df["Mission_Final"] = df.apply(
            lambda row: row.get("Modification Code Expensya") if pd.notna(row.get("Modification Code Expensya")) else row.get("Client (R√©f√©rence)"),
            axis=1
        ).fillna("").replace("", "vide")
        df["Mission_Clean"] = df["Mission_Final"].apply(nettoyer_nom)
        
        # --- ‚¨áÔ∏è Sauvegarde pour le calendrier (r√©utilisable sans upload) ---
        # 1) Normaliser Date
        df["Date"] = pd.to_datetime(df["Date"], errors="coerce")

        # 2) Construire MissionLib (si pas d√©j√† pr√©sent)
        if "Modification Code Expensya" in df.columns:
            _map = dict(zip(
                df["Client (R√©f√©rence)"].astype(str),
                df["Modification Code Expensya"].astype(str)
            ))
        else:
            _map = {}

        df["MissionLib"] = df["Client (R√©f√©rence)"].astype(str).map(_map).fillna(df["Client (R√©f√©rence)"].astype(str))

        # 3) Colonnes utiles pour le calendrier (l√©ger)
        _cal_cols = ["Date", "Nom de la d√©pense", "Cat√©gorie", "Utilisateur",
                    "Client (R√©f√©rence)", "R√©f√©rence", "MissionLib", "TTC (EUR)"]
        cal_base = df[_cal_cols].copy()

        # 4) Stocker en session
        st.session_state["cal_from_onedrive"] = cal_base
        st.session_state["mat_map"] = _map              # (optionnel) pour r√©appliquer MissionLib
        # Les justificatifs sont d√©j√† m√©moris√©s plus haut :
        # st.session_state["receipts_zip_path"], st.session_state["receipts_index"]

        # Extraire justificatifs vers un dossier
        justificatifs_dir = os.path.join(temp_dir, "justifs")
        os.makedirs(justificatifs_dir, exist_ok=True)
        with zipfile.ZipFile(inner_zip_path, "r") as zf:
            zf.extractall(justificatifs_dir)
        import os, re, zipfile
        # ... tu as d√©j√†: justificatifs_dir rempli √† partir de inner_zip_path

        def _norm_ref(s: str) -> str:
            # normalise une r√©f√©rence : garde les chiffres uniquement (ex: "Ref-009024.pdf" -> "9024")
            return re.sub(r"\D", "", str(s)).lstrip("0") or "0"

        # Construit l'index global une fois pour toutes
        receipts_index = {}

        with zipfile.ZipFile(inner_zip_path, "r") as zread:
            for name in zread.namelist():
                if name.endswith("/"):
                    continue
                base = os.path.basename(name)
                if not base:
                    continue
                # 1) si le fichier commence par la ref -> simple
                m = re.match(r"^(\d+)[\s_\-\.].*", base)
                if m:
                    ref_key = _norm_ref(m.group(1))
                    receipts_index.setdefault(ref_key, []).append(name)
                    continue
                # 2) sinon, on tente de trouver un bloc de chiffres au d√©but ou apr√®s un s√©parateur
                m2 = re.search(r"(\d{3,})", base)
                if m2:
                    ref_key = _norm_ref(m2.group(1))
                    receipts_index.setdefault(ref_key, []).append(name)

        # Sauvegarde en session pour la page calendrier
        st.session_state["receipts_zip_path"] = inner_zip_path
        st.session_state["receipts_index"] = receipts_index

        # Filtrer le DF par missions s√©lectionn√©es
        # (on compare sur la valeur brute "Client (R√©f√©rence)" ET sur "Modification Code Expensya")
        missions_lower = set(m.lower() for m in missions_selected)
        df_filt = df[
            df["Client (R√©f√©rence)"].astype(str).str.lower().isin(missions_lower) |
            df["Mission_Final"].astype(str).str.lower().isin(missions_lower)
        ].copy()

        if df_filt.empty:
            st.warning("Aucune ligne du rapport ne correspond aux missions s√©lectionn√©es.")
            st.stop()

        # --- Cr√©ation des dossiers missions ---
        grouped = df_filt.groupby("Mission_Final")

        for mission, group in grouped:
            mission_clean = nettoyer_nom(mission)
            mission_path = os.path.join(temp_dir, mission_clean)
            os.makedirs(mission_path, exist_ok=True)

            # Sauvegarde du rapport Excel par mission
            excel_path = os.path.join(mission_path, f"{mission_clean}.xlsx")
            group.to_excel(excel_path, index=False)

            # R√©partition par (mois -> user)
            for _, row in group.iterrows():
                ref = str(row.get("R√©f√©rence", "")).strip()
                user_name = nettoyer_nom(row.get("Utilisateur", "inconnu"))

                # Dossier mois (selon "Date" si dispo)
                date_val = pd.to_datetime(row.get("Date", pd.NaT), errors="coerce")
                mois_str = date_val.strftime("%B %Y") if pd.notna(date_val) else "inconnu"

                mois_dir = os.path.join(mission_path, mois_str)
                user_dir = os.path.join(mois_dir, user_name)
                os.makedirs(user_dir, exist_ok=True)

                # Copier les justificatifs correspondants (par ref)
                # On cherche les fichiers du ZIP interne qui commencent par la r√©f√©rence
                # üîé Recherche robuste des pi√®ces (parcours r√©cursif + normalisation)
                raw_ref = str(row.get("R√©f√©rence", "")).strip()
                norm_ref = re.sub(r"\D", "", raw_ref).lstrip("0") or "0"

                for root, _, files in os.walk(justificatifs_dir):
                    for file in files:
                        base = os.path.basename(file)
                        m = re.match(r"^(\d+)[\s_\-\.]", base) or re.search(r"(\d{3,})", base)
                        if not m:
                            continue
                        key = re.sub(r"\D", "", m.group(1)).lstrip("0") or "0"
                        if key != norm_ref:
                            continue

                        nom_depense = str(row.get("Nom de la d√©pense", "inconnu")).strip()
                        categorie = str(row.get("Cat√©gorie", "inconnu")).strip()
                        date_str = date_val.strftime("%Y-%m-%d") if pd.notna(date_val) else "inconnu"

                        _, ext = os.path.splitext(base)
                        new_name = f"{raw_ref}_{nom_depense}_{categorie}_{date_str}{ext}"
                        new_name = re.sub(r'[<>:"/\\|?*]', '_', new_name)

                        src = os.path.join(root, file)
                        dst = os.path.join(user_dir, new_name)
                        shutil.copy(src, dst)

        # Zippage de sortie pour t√©l√©chargement
        output = BytesIO()
        added_files = 0
        with zipfile.ZipFile(output, "w", compression=zipfile.ZIP_DEFLATED) as zipf:
            for mission in set(df_filt["Mission_Final"]):
                mission_clean = nettoyer_nom(mission)
                mission_dir = os.path.join(temp_dir, mission_clean)
                if os.path.exists(mission_dir):
                    for root, _, files in os.walk(mission_dir):
                        for file in files:
                            full_path = os.path.join(root, file)
                            rel_path = os.path.relpath(full_path, temp_dir)
                            zipf.write(full_path, rel_path)
                            added_files += 1

        if added_files > 0:
            output.seek(0)
            st.success("‚úÖ Traitement termin√©, toutes vos missions sont pr√™tes.")
            st.download_button("üì• T√©l√©charger toutes vos missions", output, file_name=f"{user}_missions.zip")
        else:
            st.warning("‚ö†Ô∏è Aucun dossier g√©n√©r√©.")
            st.write("Missions s√©lectionn√©es:", missions_selected)
            st.write("Dossiers g√©n√©r√©s:", os.listdir(temp_dir))

    except Exception as e:
        st.error(f"‚ùå Erreur : {e}")

# =============================
#     üìÖ CALENDRIER DES JUSTIFICATIFS
# =============================
# =============================
#     üìÖ CALENDRIER DES JUSTIFICATIFS
# =============================
st.divider()
st.subheader("üìÖ Calendrier des justificatifs (par date)")

st.markdown(
    "- Charge le **Rapport Expensya (.xlsx)** (onglet 'Rapport').  \n"
    "- Un **point = une d√©pense** color√©e par **Cat√©gorie**.  \n"
    "- Clique sur un point pour voir les justificatifs du jour."
)

# 1) Rapport : fichier import√© (prioritaire) OU donn√©es OneDrive d√©j√† trait√©es
cal_file = st.file_uploader(
    "Importer le fichier Rapport (.xlsx)", 
    type=["xlsx"], 
    key="cal_uploader"
)

if cal_file is not None:
    # Cas A : fichier import√©
    cal_df = pd.read_excel(cal_file, sheet_name="Rapport")
    cal_df["Date"] = pd.to_datetime(cal_df["Date"], errors="coerce")

    # MissionLib depuis le mapping global si dispo (mat_map cr√©√©e au moment du traitement OneDrive)
    map_dict = st.session_state.get("mat_map", {})
    if "MissionLib" not in cal_df.columns or cal_df["MissionLib"].isna().all():
        if map_dict:
            cal_df["MissionLib"] = (
                cal_df["Client (R√©f√©rence)"]
                .astype(str)
                .map(map_dict)
                .fillna(cal_df["Client (R√©f√©rence)"].astype(str))
            )
        else:
            cal_df["MissionLib"] = cal_df["Client (R√©f√©rence)"].astype(str)
else:
    # Cas B : r√©utiliser les donn√©es du rapport d√©j√† trait√©es depuis OneDrive
    cal_df = st.session_state.get("cal_from_onedrive")

# Garde-fou si rien n‚Äôest dispo
if cal_df is None or cal_df.empty:
    st.warning("Aucune donn√©e de calendrier disponible. Lance d'abord le traitement ou importe le Rapport.")
    st.stop()
# üîπ Filtrer strictement sur les missions s√©lectionn√©es (y compris 106710)
missions_set = {m.strip().lower() for m in missions_selected}
cal_df = cal_df[
    cal_df["Client (R√©f√©rence)"].astype(str).str.lower().isin(missions_set)
    | cal_df["MissionLib"].astype(str).str.lower().isin(missions_set)
]
# 2) Filtrer par missions s√©lectionn√©es (IMPORTANT)
missions_set = {m.strip().lower() for m in missions_selected}

cal_df = cal_df[
    cal_df["Client (R√©f√©rence)"].astype(str).str.lower().isin(missions_set)
    | cal_df["MissionLib"].astype(str).str.lower().isin(missions_set)
]


# 3) Nettoyage de base
cal_df["Date"] = pd.to_datetime(cal_df["Date"], errors="coerce")
cal_df = cal_df.dropna(subset=["Date"])

# 4) Exclure les missions NO REFACT (toutes variantes)
cal_df["MissionLib"] = cal_df["MissionLib"].astype(str)
cal_df = cal_df[~cal_df["MissionLib"].str.contains("NO REFACT", case=False, na=False)]

# Garde-fou apr√®s filtre
if cal_df.empty:
    st.warning("Apr√®s filtres (missions + NO REFACT), aucune d√©pense trouv√©e.")
    st.stop()

# 5) Pastille d‚Äô√©tat UX
if cal_file is None:
    st.caption("üü¢ Donn√©es calendrier charg√©es depuis Base donn√©es (session courante).")
else:
    st.caption("üìÑ Donn√©es calendrier charg√©es depuis le fichier import√©.")

# # 6) Matrice optionnelle (pour ajuster le libell√© mission affich√©, sans casser les filtres)
# mat_file = st.file_uploader(
#     "‚ûï (optionnel) Matrice Expensya (.xlsx) pour afficher le libell√© mission",
#     type=["xlsx"],
#     key="mat_for_cal"
# )
# client_to_label = {}
# if mat_file is not None:
#     try:
#         _mat = pd.read_excel(mat_file)
#         if {"Client (R√©f√©rence)", "Modification Code Expensya"}.issubset(_mat.columns):
#             client_to_label = dict(
#                 zip(
#                     _mat["Client (R√©f√©rence)"].astype(str),
#                     _mat["Modification Code Expensya"].astype(str),
#                 )
#             )
#     except Exception:
#         pass

# if client_to_label:
#     cal_df["MissionLib"] = (
#         cal_df["Client (R√©f√©rence)"]
#         .astype(str)
#         .map(client_to_label)
#         .fillna(cal_df["MissionLib"])
#     )

# # 7) ZIP justificatifs optionnel (pour preview / download)
# zip_for_calendar = st.file_uploader(
#     "‚ûï (optionnel) ZIP des justificatifs (export Expensya) ‚Äî pour pr√©visualiser/t√©l√©charger",
#     type=["zip"],
#     key="zip_for_calendar"
# )
# ====== DEBUG : comprendre pourquoi 228 ‚â† 216 ======
st.write("üöß DEBUG ‚Äî Lignes calendrier apr√®s filtres :", len(cal_df))

# Nombre de lignes par mission
st.write("Lignes par mission (Client (R√©f√©rence)) :")
st.dataframe(
    cal_df.groupby("Client (R√©f√©rence)")["R√©f√©rence"]
          .nunique()
          .reset_index(name="Nb_lignes")
)

# Lignes suspectes : nom contenant 'total' ou montant vide
suspect = cal_df[
    cal_df["Nom de la d√©pense"].astype(str).str.contains("total", case=False, na=False)
    | cal_df["TTC (EUR)"].isna()
]
st.write("Lignes suspectes (TOTAL / montant NaN) :")
st.dataframe(
    suspect[["R√©f√©rence", "Date", "Nom de la d√©pense", "Client (R√©f√©rence)", "MissionLib", "TTC (EUR)"]]
)

# (optionnel) export des lignes pour comparaison dans Excel
# suspect.to_excel("debug_suspect.xlsx", index=False)
# st.download_button("üì• T√©l√©charger les lignes suspectes", open("debug_suspect.xlsx","rb"), "debug_suspect.xlsx")

# 8) M√©triques (tu choisis ce que ‚ÄúD√©penses‚Äù repr√©sente)
nb_lignes = len(cal_df)
nb_refs_uniques = cal_df["R√©f√©rence"].astype(str).nunique()

col1, col2, col3 = st.columns(3)
# üëâ Si tu veux le nombre de *lignes* :
# col1.metric("D√©penses", f"{nb_lignes:,}".replace(",", " "))

# üëâ Si tu pr√©f√®res le nombre de r√©f√©rences uniques :
col1.metric("D√©penses", f"{nb_refs_uniques:,}".replace(",", " "))

col2.metric("Utilisateurs uniques", cal_df["Utilisateur"].nunique())
col3.metric("Jours distincts", cal_df["Date"].dt.date.nunique())


# Filtres
with st.expander("üéõÔ∏è Filtres"):
    users = sorted(cal_df["Utilisateur"].dropna().unique().tolist())
    cats = sorted(cal_df["Cat√©gorie"].dropna().unique().tolist())
    sel_users = st.multiselect("Utilisateurs", users, default=users)
    sel_cats = st.multiselect("Cat√©gories", cats, default=cats)
    date_min = cal_df["Date"].min().date()
    date_max = cal_df["Date"].max().date()
    date_range = st.date_input("P√©riode", (date_min, date_max))

cal_f = cal_df[
    cal_df["Utilisateur"].isin(sel_users) &
    cal_df["Cat√©gorie"].isin(sel_cats) &
    (cal_df["Date"].dt.date >= pd.to_datetime(date_range[0]).date()) &
    (cal_df["Date"].dt.date <= pd.to_datetime(date_range[-1]).date())
].copy()

if cal_f.empty:
    st.info("Aucune d√©pense ne correspond aux filtres actuels.")
    st.stop()

# ---------- Vue timeline cliquable (1 barre par utilisateur & jour) ----------

# 1) Pr√©parer un enregistrement par (Utilisateur, Jour)
ev = cal_f.copy()
ev["D√©but"] = ev["Date"].dt.floor("D")
ev["Fin"]   = ev["D√©but"] + pd.Timedelta(days=1)

# agr√©gation par jour & utilisateur
agg = (
    ev.groupby(["Utilisateur", "D√©but"])
    .agg(
        CatList = ("Cat√©gorie", lambda s: sorted(set(s))),
        MissionLib = ("MissionLib", "first"),
        Refs = ("R√©f√©rence", lambda s: list(s))
    )
    .reset_index()
)
# Cat√©gorie2 = "Mixte" si plusieurs cat√©gories le m√™me jour, sinon la seule cat√©gorie
agg["Cat√©gorie2"] = agg["CatList"].apply(lambda lst: "Mixte" if len(lst) > 1 else lst[0])
agg["Fin"] = agg["D√©but"] + pd.Timedelta(days=1)
agg["Date_str"] = agg["D√©but"].dt.strftime("%Y-%m-%d")  # pour le clic

# --- Pr√©parer texte lisible pour la bulle (hover) ---
# Convertit la liste de r√©f√©rences en une cha√Æne avec des puces
def join_refs(lst):
    if not lst:
        return ""
    return "<br>‚Ä¢ ".join(str(x) for x in lst)

# Si tu veux aussi montrer les montants par jour, construis Montants_join (optionnel)
if "TTC (EUR)" in cal_f.columns:
    ref_to_amount = cal_f.dropna(subset=["R√©f√©rence"]).drop_duplicates("R√©f√©rence").set_index("R√©f√©rence")["TTC (EUR)"].to_dict()
else:
    ref_to_amount = {}

agg["Refs_join"] = agg["Refs"].apply(lambda lst: join_refs(lst))

def join_amounts(lst):
    out = []
    for r in lst:
        amt = ref_to_amount.get(str(r), None)
        if amt is not None and pd.notna(amt):
            try:
                out.append(f"{r} : {float(amt):.2f}‚Ç¨")
            except Exception:
                out.append(f"{r} : {amt}")
        else:
            out.append(str(r))
    return ", ".join(out)

if ref_to_amount:
    agg["Montants_join"] = agg["Refs"].apply(lambda lst: join_amounts(lst))
else:
    agg["Montants_join"] = ""

# ============================================
# Timeline avec bulle lisible (Cat√©gorie ‚Äî Nom (+ montant))
# ============================================

# 1) Agr√©gation par (Utilisateur, Jour) avec une liste "Items" lisible
def _items_for_day(dfday):
    out = []
    for _, r in dfday.iterrows():
        cat = str(r.get("Cat√©gorie", "")).strip()
        nom = str(r.get("Nom de la d√©pense", "")).strip()
        amt = r.get("TTC (EUR)", None)
        if amt is not None and pd.notna(amt):
            try:
                line = f"{cat} ‚Äî {nom} ({float(amt):.2f}‚Ç¨)"
            except Exception:
                line = f"{cat} ‚Äî {nom} ({amt})"
        else:
            line = f"{cat} ‚Äî {nom}"
        out.append(line)
    return out

# Pour fabriquer "Items", on regroupe ev et on reprend les m√™mes lignes du groupe
def _items_grouped(g):
    # g est un Series de noms de d√©pense, on r√©cup√®re l'index dans ev
    return _items_for_day(ev.loc[g.index])

agg = (
    ev.groupby(["Utilisateur", "D√©but"])
    .agg(
        CatList=("Cat√©gorie", lambda s: sorted(set(s))),
        MissionLib=("MissionLib", "first"),
        Refs=("R√©f√©rence", lambda s: list(s)),                    # tu peux garder si utile ailleurs
        Items=("Nom de la d√©pense", _items_grouped)               # üëà liste lisible
    )
    .reset_index()
)

# Cat√©gorie "Mixte" si plusieurs cat√©gories le m√™me jour
# Compter le nombre de notes par (Utilisateur, Jour)
agg["NoteCount"] = agg["Items"].apply(lambda L: len(L) if isinstance(L, list) else 0)

# Si +1 note le m√™me jour => "Mixte" (m√™me si toutes les notes ont la m√™me cat√©gorie)
# Sinon, on affiche la cat√©gorie unique s'il y en a une
def _cat_mixed(row):
    if row["NoteCount"] > 1:
        return "Mixte"
    lst = row["CatList"]
    return lst[0] if isinstance(lst, list) and len(lst) >= 1 else "Inconnue"

agg["Cat√©gorie2"] = agg.apply(_cat_mixed, axis=1)

agg["Fin"] = agg["D√©but"] + pd.Timedelta(days=1)
agg["Date_str"] = agg["D√©but"].dt.strftime("%Y-%m-%d")

# Liste √† puces pour la bulle
def join_items(lst):
    if not lst:
        return ""
    return "‚Ä¢ " + "<br>‚Ä¢ ".join(str(x) for x in lst)
agg["Items_join"] = agg["Items"].apply(join_items)

# 2) Tracer la timeline avec custom_data pour le hover
import plotly.express as px
fig = px.timeline(
    agg,
    x_start="D√©but",
    x_end="Fin",
    y="Utilisateur",
    color="Cat√©gorie2",
    hover_name="Utilisateur",
    # customdata indices:
    # 0 Utilisateur, 1 Date_str, 2 Items_join, 3 MissionLib, 4 Cat√©gorie2
    custom_data=["Utilisateur", "Date_str", "Items_join", "MissionLib", "Cat√©gorie2"],
    color_discrete_sequence=px.colors.qualitative.Set2
)
fig.update_yaxes(autorange="reversed")

# Hachurer les jours Mixte
for tr in fig.data:
    if tr.name == "Mixte":
        tr.marker.pattern.shape = "/"
        tr.marker.pattern.fillmode = "overlay"
        tr.marker.line.width = 0.6

# 3) Bulle personnalis√©e
hover_template = (
    "<b>%{customdata[0]}</b> ‚Äî %{customdata[1]}<br>"
    "Mission : %{customdata[3]}<br><br>"
    "%{customdata[2]}"                    # liste √† puces (Items_join)
    "<extra></extra>"
)
fig.update_traces(hovertemplate=hover_template)

# 4) Mise en forme & affichage
fig.update_layout(
    height=520,
    margin=dict(l=20, r=20, t=30, b=20),
    xaxis_title="Date",
    yaxis_title="Utilisateur",
    legend_title_text="Cat√©gorie (Mixte = plusieurs cat√©gories le m√™me jour)",
    uirevision="cal_v1"
)
st.plotly_chart(fig, use_container_width=True)




# Index justificatifs si ZIP fourni
# --------- Acc√®s aux justificatifs ---------
ref_files = {}
zf = None

# # 1) Cas A : l'utilisateur a upload√© un ZIP -> priorit√©
# if zip_for_calendar is not None:
#     try:
#         zf = zipfile.ZipFile(zip_for_calendar)
#         # (re)construit l'index √† partir de l'upload
#         ref_files = {}
#         for name in zf.namelist():
#             base = os.path.basename(name)
#             if not base:
#                 continue
#             # m√™me normalisation que plus haut
#             m = re.match(r"^(\d+)[\s_\-\.].*", base) or re.search(r"(\d{3,})", base)
#             if m:
#                 key = re.sub(r"\D","", m.group(1)).lstrip("0") or "0"
#                 ref_files.setdefault(key, []).append(name)
#     except Exception as e:
#         st.warning(f"Impossible de lire le ZIP justificatifs upload√© : {e}")
#         zf = None

# 2) Cas B : aucun upload -> on r√©utilise l'index et le ZIP internes OneDrive
if zf is None and "receipts_zip_path" in st.session_state and "receipts_index" in st.session_state:
    try:
        internal_zip = st.session_state["receipts_zip_path"]
        zf = zipfile.ZipFile(internal_zip)
        ref_files = st.session_state.get("receipts_index", {})
    except Exception as e:
        st.warning(f"Impossible d'ouvrir le ZIP interne OneDrive : {e}")
        zf = None
        ref_files = {}

# =============================
# üì¶ Exporter justificatifs par utilisateur / p√©riode
# (√† placer apr√®s la construction de `ref_files` et `zf`, avant l'expander "D√©tails des jours...")
# =============================
st.markdown("### üì¶ Exporter les justificatifs par utilisateur et p√©riode")

if zf is None:
    st.info("‚û°Ô∏è Pour activer l'export, fournis le **ZIP des justificatifs** (ou ex√©cute le traitement OneDrive).")
else:
    # S√©lection des utilisateurs (par d√©faut ceux visibles dans le calendrier filtr√©)
    users_export = sorted(cal_f["Utilisateur"].dropna().unique().tolist())
    pick_users = st.multiselect("Utilisateurs √† inclure", users_export, default=users_export)

    # S√©lection de la p√©riode (par d√©faut la m√™me que les filtres actuels)
    date_min_exp = cal_f["Date"].min().date()
    date_max_exp = cal_f["Date"].max().date()
    dr_export = st.date_input("P√©riode d'export", (date_min_exp, date_max_exp), key="export_period")

    # Filtrer les lignes √† exporter
    df_export = cal_f[
        cal_f["Utilisateur"].isin(pick_users) &
        (cal_f["Date"].dt.date >= pd.to_datetime(dr_export[0]).date()) &
        (cal_f["Date"].dt.date <= pd.to_datetime(dr_export[-1]).date())
    ].copy()

    st.caption(f"üßæ {len(df_export)} notes de frais retenues pour l'export.")

    # Lancer l'export
    col_exp_btn, _ = st.columns([1,4])
    if col_exp_btn.button("üì• G√©n√©rer le ZIP des justificatifs", key="btn_export_zip"):
        from io import BytesIO
        import re, os, zipfile

        out = BytesIO()
        added, missing = 0, 0

        with zipfile.ZipFile(out, "w", compression=zipfile.ZIP_DEFLATED) as zout:
            for _, r in df_export.iterrows():
                raw_ref = str(r.get("R√©f√©rence", "")).strip()
                norm_ref = re.sub(r"\D", "", raw_ref).lstrip("0") or "0"
                user     = re.sub(r'[<>:"/\\|?*]', "_", str(r.get("Utilisateur", "inconnu")).strip())
                date_day = r["Date"].strftime("%Y-%m-%d")
                mission  = str(r.get("MissionLib", r.get("Client (R√©f√©rence)", "mission"))).strip()
                mission  = re.sub(r'[<>:"/\\|?*]', "_", mission)

                files = ref_files.get(norm_ref, [])

                if not files:
                    missing += 1
                    continue

                for path in files:
                    data = zf.read(path)
                    base = os.path.basename(path)

                    # renommage + arborescence ZIP : Utilisateur/Date/Mission/nomfichier
                    # (tu peux simplifier si tu veux)
                    arcname = f"{user}/{date_day}/{mission}/{base}"
                    zout.writestr(arcname, data)
                    added += 1

        if added == 0:
            st.warning("Aucun fichier n'a pu √™tre ajout√© (r√©f√©rences introuvables dans le ZIP).")
        else:
            out.seek(0)
            st.success(f"‚úÖ ZIP pr√™t : {added} fichier(s) ajout√©(s)" + (f", {missing} r√©f√©rence(s) sans pi√®ce" if missing else ""))
            st.download_button(
                "‚¨áÔ∏è T√©l√©charger le ZIP export",
                out,
                file_name="justificatifs_export.zip",
                mime="application/zip",
                key="dl_export_zip"
            )
# =============================
# üîé S√©lection manuelle (fallback) + Preview justificatifs
# =============================
st.markdown("### üîé S√©lection manuelle (fallback)")

# 1) Choix utilisateur puis jour (selon cal_f d√©j√† filtr√©)
users_opts = ["‚Äî"] + sorted(cal_f["Utilisateur"].dropna().unique().tolist())
user_pick = st.selectbox("Utilisateur", users_opts, index=0, key="fallback_user")

day_pick = "‚Äî"
if user_pick != "‚Äî":
    day_opts = ["‚Äî"] + sorted(
        cal_f.loc[cal_f["Utilisateur"] == user_pick, "Date"].dt.strftime("%Y-%m-%d").unique().tolist()
    )
    day_pick = st.selectbox("Jour", day_opts, index=0, key="fallback_day")

# 2) D√©tails + preview si on a un couple valide
if user_pick != "‚Äî" and day_pick != "‚Äî":
    st.subheader(f"üóÇÔ∏è D√©tails pour {user_pick} ‚Äî {day_pick}")

    clicked_df = cal_f[
        (cal_f["Utilisateur"] == user_pick) &
        (cal_f["Date"].dt.strftime('%Y-%m-%d') == day_pick)
    ].sort_values("Date")

    if clicked_df.empty:
        st.info("Aucune note de frais pour ce point.")
    else:
        import base64, os

        for i, r in clicked_df.iterrows():
            ref = str(r.get("R√©f√©rence", "")).strip()
            mission_txt = r.get("MissionLib", r.get("Client (R√©f√©rence)", ""))
            montant = ""
            if "TTC (EUR)" in r and pd.notna(r["TTC (EUR)"]):
                try:
                    montant = f" ‚Äî {float(r['TTC (EUR)']):.2f} EUR"
                except Exception:
                    pass


            with st.expander(
                f"üìÑ {r['Cat√©gorie']} ¬∑ {r['Nom de la d√©pense']}{montant} ¬∑ _Mission : {mission_txt}_",
                expanded=True if len(clicked_df) == 1 else False
            ):
                st.write(f"**R√©f√©rence** : `{ref}`")
                if pd.notna(r["Date"]):
                    st.write(f"**Heure** : {r['Date'].strftime('%H:%M')}")

                if zf is None:
                    st.caption("üõà Fournis le ZIP des justificatifs ci-dessus pour pr√©visualiser et t√©l√©charger les fichiers.")
                else:
                    # 1) Trouver les pi√®ces li√©es √† la r√©f√©rence
                    norm_ref = re.sub(r"\D", "", ref).lstrip("0") or "0"
                    files = ref_files.get(norm_ref, [])

                    if not files:
                        st.warning("Aucune pi√®ce jointe trouv√©e pour cette r√©f√©rence.")
                    else:
                        # 2) <<< ICI LE SLIDER DE TAILLE >>>
                        prev_h = st.slider(
                            "Taille de pr√©visualisation (px)",
                            min_value=150,
                            max_value=900,
                            value=340,
                            step=10,
                            key=f"prev_h_{ref or i}"
                        )

                        # 3) Affichage des pi√®ces : aper√ßu + Voir en grand + T√©l√©charger
                        # --- juste avant la boucle des fichiers
                        import streamlit.components.v1 as components
                        import base64

                        for j, path in enumerate(files):
                            data = zf.read(path)
                            name = os.path.basename(path)
                            ext = name.lower().split(".")[-1]

                            # 1) placeholder plein-largeur pour l‚Äôaffichage "grand"
                            row_key = f"{norm_ref}_{j}"
                            viewer_ph = st.empty()   # on y rendra le grand affichage si demand√©

                            # 2) ligne de contr√¥les : Aper√ßu + Voir en grand + T√©l√©charger
                            c_preview, c_view, c_dl = st.columns([6, 2, 2])

                            if ext in ("jpg", "jpeg", "png", "gif", "webp"):
                                # Aper√ßu image (contr√¥l√© par le slider prev_h)
                                with c_preview:
                                    st.image(data, caption=name, width=prev_h)

                                # Bouton "Voir en grand"
                                with c_view:
                                    if st.button("üëÅÔ∏è Voir en grand", key=f"view_img_{row_key}"):
                                        st.session_state[f"open_{row_key}"] = True

                                # T√©l√©chargement
                                with c_dl:
                                    st.download_button("‚¨áÔ∏è T√©l√©charger", data, file_name=name, key=f"dl_img_{row_key}")

                                # Rendu plein √©cran (en dehors des colonnes)
                                if st.session_state.get(f"open_{row_key}"):
                                    with viewer_ph.container():
                                        st.markdown(f"### üîé {name}")
                                        st.image(data, use_container_width=True)
                                        if st.button("Fermer", key=f"close_img_{row_key}"):
                                            st.session_state[f"open_{row_key}"] = False
                                            viewer_ph.empty()

                            elif ext == "pdf":
                                b64 = base64.b64encode(data).decode("utf-8")

                                # Aper√ßu PDF (hauteur contr√¥l√©e par le slider)
                                with c_preview:
                                    components.html(
                                        f'<iframe src="data:application/pdf;base64,{b64}" '
                                        f'width="100%" height="{prev_h}px" style="border:0;"></iframe>',
                                        height=prev_h + 20,
                                        scrolling=True
                                    )

                                # Bouton "Voir en grand"
                                with c_view:
                                    if st.button("üëÅÔ∏è Voir en grand", key=f"view_pdf_{row_key}"):
                                        st.session_state[f"open_{row_key}"] = True

                                # T√©l√©chargement
                                with c_dl:
                                    st.download_button("‚¨áÔ∏è T√©l√©charger", data, file_name=name, key=f"dl_pdf_{row_key}")

                                # Rendu plein √©cran (en dehors des colonnes)
                                if st.session_state.get(f"open_{row_key}"):
                                    with viewer_ph.container():
                                        st.markdown(f"### üîé {name}")
                                        components.html(
                                            f'<iframe src="data:application/pdf;base64,{b64}" '
                                            f'width="100%" height="800px" style="border:0;"></iframe>',
                                            height=820,
                                            scrolling=True
                                        )
                                        if st.button("Fermer", key=f"close_pdf_{row_key}"):
                                            st.session_state[f"open_{row_key}"] = False
                                            viewer_ph.empty()

                            else:
                                with c_preview:
                                    st.caption(f"Aper√ßu indisponible pour ¬´ .{ext} ¬ª.")
                                with c_view:
                                    st.button("üëÅÔ∏è Voir en grand", key=f"view_other_{row_key}", disabled=True)
                                with c_dl:
                                    st.download_button("‚¨áÔ∏è T√©l√©charger", data, file_name=name, key=f"dl_other_{row_key}")



# Jours multi-notes (optionnel)
with st.expander("üîé D√©tails des jours avec plusieurs notes de frais"):
    tmp = cal_f.copy()
    tmp["Jour"] = tmp["Date"].dt.floor("D")
    g = tmp.groupby(["Utilisateur", "Jour"]).size().reset_index(name="count")
    multi = g[g["count"] > 1].sort_values(["Utilisateur", "Jour"])
    if multi.empty:
        st.write("Aucun jour ne contient plusieurs notes de frais.")
    else:
        for _, row in multi.iterrows():
            u, d = row["Utilisateur"], row["Jour"]
            sub = tmp[(tmp["Utilisateur"] == u) & (tmp["Jour"] == d)].sort_values("Date")
            st.markdown(
                f"**{u} ‚Äî {d.strftime('%Y-%m-%d')}**  \n"
                f"_Cat√©gories:_ {', '.join(sorted(set(sub['Cat√©gorie'])))}  \n"
                f"_Nombre de notes:_ {len(sub)}"
            )
            for _, r in sub.iterrows():
                montant = ""
                if "TTC (EUR)" in r and pd.notna(r["TTC (EUR)"]):
                    montant = f" ‚Äî {r['TTC (EUR)']:.2f} EUR"
                st.write(f"- **{r['Cat√©gorie']}** ¬∑ {r['Nom de la d√©pense']}{montant}")




# =============================
#      PIED DE PAGE
# =============================
st.markdown("""
<div style="text-align: center; color: #666; padding: 2rem; margin-top: 3rem; 
background: linear-gradient(to right, #f8f9fa, #e9ecef); border-radius: 10px;">
    <p style="font-size: 1.2rem; margin-bottom: 0.5rem;">
            <strong>ADVENT+ - Expensya Justificatifs Manager</strong>
    </p>
    <p style="margin-bottom: 0.5rem;">Internal Distribution Analysis & Automation Platform - v1.0</p>
    <p style="font-size: 0.9rem; margin-top: 0.8rem;">
        üîπ G√©n√©ration automatique de dossiers missions ‚Ä¢ <br>
        üîπ Gestion s√©curis√©e des justificatifs clients ‚Ä¢ <br>
        üîπ Int√©gration OneDrive & Expensya ‚Ä¢ <br>
        üîπ Contr√¥le utilisateur par authentification
    </p>
    <p style="font-size: 0.8rem; margin-top: 1rem;">
        <strong>üîí Confidentialit√© :</strong> Usage interne r√©serv√© √† <b>ADVENT+</b> ‚Ä¢ 
        Acc√®s restreint par login/mot de passe
    </p>
</div>
""", unsafe_allow_html=True)
