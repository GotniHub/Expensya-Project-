import streamlit as st
import pandas as pd
import zipfile
import os
import shutil
import re
import requests
from io import BytesIO

st.set_page_config(page_title="Gestion des Missions", layout="wide")
st.logo("LOGO.png", icon_image="Logom.png")
st.title("üìÇ G√©n√©rateur et acc√®s aux dossiers missions")
# Init session keys
if "receipts_index" not in st.session_state:
    st.session_state["receipts_index"] = {}

# V√©rifier la connexion
if "auth_user" not in st.session_state or st.session_state["auth_user"] is None:
    st.warning("‚ö†Ô∏è Aucun utilisateur connect√©. Veuillez d‚Äôabord vous connecter depuis la page **Home**.")
    st.stop()

# Si connect√©
user = st.session_state["auth_user"]
missions = st.session_state.get("missions", [])
# Choix mission
if len(missions) == 1:
    missions_selected = missions  # liste avec une seule mission
    st.info(f"‚úÖ Mission assign√©e automatiquement : {missions[0]}")
else:
    missions_selected = st.multiselect(
        "üìå S√©lectionnez vos missions :", missions, default=missions
    )
    if missions_selected:
        st.success(f"Missions s√©lectionn√©es : {', '.join(missions_selected)}")
    else:
        st.warning("‚ö†Ô∏è Aucune mission s√©lectionn√©e, merci d'en choisir au moins une.")
        st.stop()


user = st.session_state.get("auth_user", "Invit√©")

# Bloc utilisateur avec design 3D Advent+
card_html = f"""
<div style="
    background: linear-gradient(135deg, rgba(30,45,80,0.75), rgba(46,134,193,0.75)); 
    color: white; 
    padding: 1.2rem; 
    border-radius: 12px;
    text-align: center;
    margin-bottom: 1.5rem;
    box-shadow: 0 6px 15px rgba(0,0,0,0.25);
    transform: perspective(1000px) rotateX(2deg) rotateY(-1deg);
">
    <h4 style="margin: 0; font-size: 1.2rem; font-weight: bold;">üë§ {user}</h4>
    <p style="margin: 0; font-size: 0.9rem; opacity: 0.95;">‚úîÔ∏è  Connect√© avec succ√®s</p>
</div>
"""

st.sidebar.markdown(card_html, unsafe_allow_html=True)


# Bouton d√©connexion styl√©
if st.sidebar.button("üö™ D√©connexion"):
    st.session_state["auth_user"] = None
    st.switch_page("home.py")

# -------------------------
# Lien OneDrive (exemple)
# -------------------------
# Exctraction S2 2024 :
# ONEDRIVE_URL = "https://adventplus-my.sharepoint.com/:u:/g/personal/igotni_adv-sud_fr/EahoQ8gXXhJLpKJy4FtfyvsBsKc7r60cII0KbVjkorzH6g?download=1"
# -------------------------
# -------------------------
# Exctraction S1 2025 :
# ONEDRIVE_URL = "https://adventplus-my.sharepoint.com/:u:/g/personal/igotni_adv-sud_fr/EQ0stgyyDlREjlnsVaUZ01sBQZEoWnscCqhuPEM5iPEmcQ?download=1" #old
ONEDRIVE_URL = "https://adventplus-my.sharepoint.com/:u:/g/personal/igotni_adv-sud_fr/Ef8LL-Y_mNhOlCQlKHlQs1wBXzoorlA-dVNmoZ07zj3oNw?download=1"

# -------------------------

# Extraction TR S1 2025 :

# ONEDRIVE_URL = "https://adventplus-my.sharepoint.com/:u:/g/personal/igotni_adv-sud_fr/EVAEu6MEKhVOqn3UhLlYSyEBNOF9OuzIaUxNd0zjqFLqaw?download=1"
# -------------------------

# Traitement
# -------------------------
def nettoyer_nom(nom):
    """Nettoie les noms de dossiers/fichiers pour compatibilit√© cross-OS."""
    return re.sub(r'[<>:"/\\|?*]', "_", str(nom).strip()).lower()
from collections import defaultdict
import zipfile, os, re
from io import BytesIO

def normaliser_ref(x) -> str:
    s = str(x).strip()
    try:
        s = s.replace(",", ".")
        f = float(s); i = int(f)
        if f == float(i):
            return str(i)
    except Exception:
        pass
    if "." in s:
        s = s.split(".", 1)[0]
    return s

def build_receipts_index_from_zipfile(zip_path: str) -> dict[str, list[tuple[str, bytes]]]:
    idx = defaultdict(list)
    with zipfile.ZipFile(zip_path, "r") as z:
        for name in z.namelist():
            if name.endswith("/"):      # ignorer les dossiers
                continue
            base = os.path.basename(name)
            if not base:
                continue
            m = re.match(r"^(\d+)", base)   # r√©f = chiffres au d√©but du nom
            if not m:
                continue
            ref = m.group(1)
            try:
                data = z.read(name)        # bytes du fichier
            except Exception:
                continue
            idx[ref].append((base, data))
    return idx

if st.button("üöÄ Lancer le traitement"):
    try:
        st.info("‚è≥ T√©l√©chargement du ZIP depuis Base de donn√©es...")

        # Cr√©er une barre de progression
        progress_bar = st.progress(0)
        status_text = st.empty()

        # √âtape 1 : t√©l√©chargement
        response = requests.get(ONEDRIVE_URL, stream=True)
        if response.status_code != 200:
            st.error("‚ùå Erreur lors du t√©l√©chargement OneDrive")
            st.stop()

        total_size = int(response.headers.get('content-length', 0))
        downloaded_size = 0
        zip_content = BytesIO()

        for chunk in response.iter_content(chunk_size=8192):
            if chunk:
                zip_content.write(chunk)
                downloaded_size += len(chunk)
                progress = int(downloaded_size / total_size * 100)
                progress_bar.progress(progress)
                status_text.text(f"T√©l√©chargement... {progress}%")

        progress_bar.progress(100)
        status_text.text("‚úÖ T√©l√©chargement termin√©. Traitement en cours...")

        # Continue ton traitement avec zip_content
        zip_content.seek(0)

        # Cr√©er dossier temporaire
        temp_dir = "temp_result"
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        os.makedirs(temp_dir)

        # Sauvegarde du ZIP principal √† partir de zip_content
        outer_zip_path = os.path.join(temp_dir, "S1 2025 extract NV.zip")
        with open(outer_zip_path, "wb") as f:
            f.write(zip_content.getvalue())


        # Extraction du ZIP principal
        with zipfile.ZipFile(outer_zip_path, "r") as outer_zip:
            outer_zip.extractall(temp_dir)

        # Identifier les fichiers (rapport, matrice, zip interne)
        rapport_file, mapping_file, inner_zip_path = None, None, None
        for file in os.listdir(temp_dir):
            if file.endswith(".xlsx") and "Matrice" in file:
                mapping_file = os.path.join(temp_dir, file)
            elif file.endswith(".xlsx"):
                rapport_file = os.path.join(temp_dir, file)
            elif file.endswith(".zip"):
                inner_zip_path = os.path.join(temp_dir, file)

        if not rapport_file or not mapping_file or not inner_zip_path:
            st.error("‚ùå Impossible de trouver Rapport, Matrice ou le ZIP interne")
            st.stop()
        # Build receipts index directly from the inner ZIP (handles subfolders)
        st.session_state["receipts_index"] = build_receipts_index_from_zipfile(inner_zip_path)
        st.success(f"üîç Index justificatifs construit pour {len(st.session_state['receipts_index'])} r√©f√©rences.")
        st.info(f"üìÑ Total fichiers justificatifs: {sum(len(v) for v in st.session_state['receipts_index'].values())}")

        # Extraire le ZIP interne (justificatifs)
        justificatifs_dir = os.path.join(temp_dir, "justifs")
        with zipfile.ZipFile(inner_zip_path, "r") as inner_zip:
            inner_zip.extractall(justificatifs_dir)

        # Charger fichiers Excel
        df = pd.read_excel(rapport_file, sheet_name="Rapport")
        df_map = pd.read_excel(mapping_file, sheet_name="Matrice Expensya")

        # V√©rification colonnes
        if not all(col in df.columns for col in ["R√©f√©rence", "Utilisateur", "Client (R√©f√©rence)"]):
            st.error("‚ùå Colonnes manquantes dans Rapport")
            st.stop()
        if not all(col in df_map.columns for col in ["Client (R√©f√©rence)", "Modification Code Expensya"]):
            st.error("‚ùå Colonnes manquantes dans Matrice Expensya")
            st.stop()

        # Fusion
        df = df.merge(
            df_map[["Client (R√©f√©rence)", "Modification Code Expensya"]],
            on="Client (R√©f√©rence)",
            how="left"
        )

        # Retirer "Grand Totale"
        if df.tail(1).astype(str).apply(lambda x: x.str.contains("Grand Totale", case=False).any(), axis=1).any():
            df = df.iloc[:-1]

        # Mission finale
        df["Mission_Final"] = df.apply(
            lambda row: row["Modification Code Expensya"] if pd.notna(row["Modification Code Expensya"]) else row["Client (R√©f√©rence)"],
            axis=1
        ).fillna("").replace("", "vide")
        df["Mission_Clean"] = df["Mission_Final"].apply(lambda x: nettoyer_nom(x).lower())

        # Split
        grouped = df.groupby("Mission_Final")
        missions_selected = [nettoyer_nom(m) for m in missions_selected]

        # --- Cr√©ation des dossiers missions ---
        for mission, group in grouped:
            mission_clean = nettoyer_nom(mission)
            mission_path = os.path.join(temp_dir, mission_clean)
            os.makedirs(mission_path, exist_ok=True)

            # Sauvegarde du rapport Excel
            excel_path = os.path.join(mission_path, f"{mission_clean}.xlsx")
            group.to_excel(excel_path, index=False)

            justificatifs_dir = os.path.join(temp_dir, "justifs")

            for _, row in group.iterrows():
                ref = str(row["R√©f√©rence"]).strip()
                user_name = nettoyer_nom(row["Utilisateur"])

                # --- Nouveau : cr√©er un dossier par mois ---
                if "Date" in df.columns:
                    try:
                        date_val = pd.to_datetime(row["Date"], errors="coerce")
                        mois_str = date_val.strftime("%B %Y") if pd.notna(date_val) else "inconnu"
                    except Exception:
                        mois_str = "inconnu"
                else:
                    mois_str = "inconnu"

                mois_dir = os.path.join(mission_path, mois_str)
                user_dir = os.path.join(mois_dir, user_name)
                os.makedirs(user_dir, exist_ok=True)

                # Copier les justificatifs correspondants
                # Copier les justificatifs correspondants
                ref = normaliser_ref(row.get("R√©f√©rence", ""))
                matching_files = st.session_state.get("receipts_index", {}).get(ref, [])

                for (orig_name, data) in matching_files:
                    nom_depense = str(row.get("Nom de la d√©pense", "inconnu")).strip()
                    categorie = str(row.get("Cat√©gorie", "inconnu")).strip()
                    try:
                        date_val = pd.to_datetime(row.get("Date"), errors="coerce").strftime("%Y-%m-%d")
                    except Exception:
                        date_val = "inconnu"

                    _, ext = os.path.splitext(orig_name)
                    new_name = f"{ref}_{nom_depense}_{categorie}_{date_val}{ext}"
                    new_name = re.sub(r'[<>:\"/\\|?*]', '_', new_name)

                    with open(os.path.join(user_dir, new_name), "wb") as f:
                        f.write(data)






        output = BytesIO()
        added_files = 0

        with zipfile.ZipFile(output, "w") as zipf:
            for mission in missions_selected:
                mission_clean = nettoyer_nom(mission)
                mission_dir = os.path.join(temp_dir, mission_clean)

                if os.path.exists(mission_dir):
                    for root, _, files in os.walk(mission_dir):
                        for file in files:
                            full_path = os.path.join(root, file)
                            rel_path = os.path.relpath(full_path, temp_dir)
                            zipf.write(full_path, rel_path)
                            added_files += 1
                else:
                    st.write(f"üö´ Mission non trouv√©e : {mission_clean}")

        if added_files > 0:
            output.seek(0)
            st.success("‚úÖ Traitement termin√©, toutes vos missions sont pr√™tes.")
            st.download_button("üì• T√©l√©charger toutes vos missions", output, file_name=f"{user}_missions.zip")
        else:
            st.warning("‚ö†Ô∏è Aucun dossier trouv√© pour votre compte.")

            st.write("Missions s√©lectionn√©es:", missions_selected)
            st.write("Dossiers g√©n√©r√©s:", os.listdir(temp_dir))




    except Exception as e:
        
        st.error(f"‚ùå Erreur : {e}")
# =============================
#     üìÖ CALENDRIER DES JUSTIFICATIFS
# =============================
st.divider()
st.subheader("üìÖ Calendrier des justificatifs (par date)")

st.markdown(
    "- Charge le **Rapport Expensya (.xlsx)** (la m√™me feuille 'Rapport' que tu utilises).  \n"
    "- Le graphique affiche chaque d√©pense √† sa date, color√©e par **Cat√©gorie**.  \n"
    "- Filtrage automatique sur tes missions s√©lectionn√©es."
)

cal_file = st.file_uploader("Importer le fichier Rapport (.xlsx)", type=["xlsx"], key="cal_uploader")

if cal_file is not None:
    try:
        cal_df = pd.read_excel(cal_file, sheet_name="Rapport")

        # Colonnes minimales requises
        required_cols = ["Date", "Nom de la d√©pense", "Cat√©gorie", "Utilisateur", "Client (R√©f√©rence)"]
        missing = [c for c in required_cols if c not in cal_df.columns]
        if missing:
            st.error(f"Colonnes manquantes dans le Rapport pour le calendrier : {missing}")
        else:
            # Normalisation
            cal_df["Date"] = pd.to_datetime(cal_df["Date"], errors="coerce")
            cal_df = cal_df.dropna(subset=["Date"])
            cal_df["Client (R√©f√©rence)"] = cal_df["Client (R√©f√©rence)"].astype(str)

            # Filtre sur les missions choisies dans l'appli (m√™mes valeurs qu‚Äôen haut)
            missions_set = set([m.strip().lower() for m in st.session_state.get("missions", [])])
            # Dans ton flux, tu utilises "Mission_Final" plus tard. Ici on se cale sur la colonne d‚Äôorigine :
            cal_df = cal_df[cal_df["Client (R√©f√©rence)"].str.lower().isin(missions_set) | (len(missions_set) == 0)]

            if cal_df.empty:
                st.warning("Aucune d√©pense trouv√©e pour les missions s√©lectionn√©es dans ce fichier.")
            else:
                # Quelques m√©triques utiles
                col1, col2, col3 = st.columns(3)
                col1.metric("D√©penses", f"{len(cal_df):,}".replace(",", " "))
                col2.metric("Utilisateurs uniques", cal_df["Utilisateur"].nunique())
                col3.metric("Jours distincts", cal_df["Date"].dt.date.nunique())

                # S√©lecteurs
                with st.expander("üéõÔ∏è Filtres"):
                    users = sorted(cal_df["Utilisateur"].dropna().unique().tolist())
                    cats = sorted(cal_df["Cat√©gorie"].dropna().unique().tolist())
                    sel_users = st.multiselect("Utilisateurs", users, default=users)
                    sel_cats = st.multiselect("Cat√©gories", cats, default=cats)
                    date_min = cal_df["Date"].min().date()
                    date_max = cal_df["Date"].max().date()
                    date_range = st.date_input("P√©riode", (date_min, date_max))

                # Application des filtres
                cal_f = cal_df[
                    cal_df["Utilisateur"].isin(sel_users) &
                    cal_df["Cat√©gorie"].isin(sel_cats) &
                    (cal_df["Date"].dt.date >= pd.to_datetime(date_range[0]).date()) &
                    (cal_df["Date"].dt.date <= pd.to_datetime(date_range[-1]).date())
                ]

                if cal_f.empty:
                    st.info("Aucune d√©pense ne correspond aux filtres actuels.")
                else:
                    # Pr√©pare une ‚Äútimeline‚Äù √† la journ√©e (√©v√©nements d‚Äôune seule journ√©e)
                    # On peut colorer par Cat√©gorie et grouper par Utilisateur
                    events = cal_f.copy()
                    events["D√©but"] = events["Date"].dt.floor("D")
                    events["Fin"] = events["Date"].dt.floor("D") + pd.Timedelta(days=1)

                    # Titre d‚Äôinfo pour le survol
                    # ---------- (OPTIONNEL) Matrice pour libell√© mission ----------
                    mat_file = st.file_uploader(
                        "‚ûï (optionnel) Matrice Expensya (.xlsx) pour afficher le libell√© mission",
                        type=["xlsx"],
                        key="mat_for_cal"
                    )

                    # 1) Charger la matrice si fournie -> construire un mapping client -> label
                    client_to_label = {}
                    if mat_file is not None:
                        try:
                            _mat = pd.read_excel(mat_file, sheet_name="Matrice Expensya")
                            if {"Client (R√©f√©rence)", "Modification Code Expensya"}.issubset(_mat.columns):
                                client_to_label = dict(
                                    zip(_mat["Client (R√©f√©rence)"].astype(str),
                                        _mat["Modification Code Expensya"].astype(str))
                                )
                        except Exception:
                            pass  # si la matrice n'est pas valide, on ignore

                    # 2) Cr√©er TOUJOURS la colonne MissionLib (m√™me sans matrice)
                    cal_f["MissionLib"] = (
                        cal_f["Client (R√©f√©rence)"].astype(str)
                            .map(client_to_label)
                            .fillna(cal_f["Client (R√©f√©rence)"].astype(str))
                    )

                    # ---------- (OPTIONNEL) ZIP des justificatifs pour aper√ßu & export ----------
                    zip_justifs = st.file_uploader(
                        "‚ûï (optionnel) ZIP des justificatifs Expensya (celui contenant les PDFs/IMG)",
                        type=["zip"],
                        key="zip_for_cal"
                    )

                    receipts_index = {}   # dict: ref -> list[(filename: str, bytes: b'...')]
                    if zip_justifs is not None:
                        try:
                            import zipfile, os
                            from io import BytesIO
                            with zipfile.ZipFile(zip_justifs) as z:
                                for name in z.namelist():
                                    if name.endswith("/"):  # ignore folders
                                        continue
                                    base = os.path.basename(name)
                                    if not base: 
                                        continue
                                    ref = base.split("_", 1)[0].strip()  # fichiers "REF_..."
                                    try:
                                        data = z.read(name)
                                    except Exception:
                                        continue
                                    receipts_index.setdefault(ref, []).append((base, data))
                            st.success(f"Justificatifs charg√©s : {sum(len(v) for v in receipts_index.values())} fichier(s).")
                        except Exception as e:
                            st.warning(f"Impossible de lire le ZIP justificatifs : {e}")


    except Exception as e:
        st.error(f"Erreur lors de la construction du calendrier : {e}")
# ---- Remplace tout "timeline" actuel par ce bloc ----

# 1) Construire une ligne par jour/utilisateur (agr√©g√©e)
tmp = cal_f.copy()
tmp["Jour"] = tmp["Date"].dt.floor("D")

def to_item_row(r):
    # Texte de d√©tail par ligne
    montant = ""
    if "TTC (EUR)" in r and pd.notna(r["TTC (EUR)"]):
        montant = f" ‚Äî {r['TTC (EUR)']:.2f} EUR"
    elif "TTC" in r and pd.notna(r["TTC"]):
        montant = f" ‚Äî {r['TTC']}"
    return f"‚Ä¢ {r['Cat√©gorie']} ¬∑ {r['Nom de la d√©pense']}{montant}"

g = (
    tmp
    .sort_values(["Utilisateur","Jour","Date"])
    .groupby(["Utilisateur","Jour"], as_index=False)
    .agg(
        count=("Nom de la d√©pense", "size"),
        cat_unique=("Cat√©gorie", lambda s: list(pd.unique(s))),
        items=("Nom de la d√©pense", lambda _: None)  # placeholder pour map
    )
)

# ‚ÄúMixte‚Äù si plusieurs cat√©gories ce jour-l√†
g["Cat√©gorie"] = g["cat_unique"].apply(lambda cats: cats[0] if len(cats)==1 else "Mixte")

# Fabriquer le hover d√©taill√© (avec la Mission)
idx_cols = ["Utilisateur","Jour"]

# on inclut MissionLib pour l'afficher dans le hover
cols_for_hover = ["Cat√©gorie", "Nom de la d√©pense", "Date", "MissionLib"]
day_rows = tmp[idx_cols + cols_for_hover].copy()

def to_item_row(r):
    montant = ""
    if "TTC (EUR)" in tmp.columns and pd.notna(r.get("TTC (EUR)")):
        montant = f" ‚Äî {r['TTC (EUR)']:.2f} EUR"
    elif "TTC" in tmp.columns and pd.notna(r.get("TTC")):
        montant = f" ‚Äî {r['TTC']}"
    return f"‚Ä¢ {r['Cat√©gorie']} ¬∑ {r['Nom de la d√©pense']}{montant}"

def build_hover(u, d):
    sub = day_rows[(day_rows["Utilisateur"]==u) & (day_rows["Jour"]==d)]
    # missions du jour (unicit√©)
    missions = sorted(set(sub["MissionLib"].astype(str)))
    mission_txt = " / ".join(missions) if missions else "‚Äî"
    # corps (liste des notes)
    lines = [to_item_row(r) for _, r in sub.iterrows()]
    title = f"{u} ‚Äî {d.strftime('%Y-%m-%d')}<br><b>Mission :</b> {mission_txt}"
    return title + "<br>" + "<br>".join(lines)

g["hover"] = [build_hover(u, d) for u, d in zip(g["Utilisateur"], g["Jour"])]


# Une barre ‚Äúd'une journ√©e‚Äù
g["D√©but"] = g["Jour"]
g["Fin"] = g["Jour"] + pd.Timedelta(days=1)

# Pattern (bandes) si plusieurs notes de frais
# (Plotly accepte un array pour pattern_shape par point)
g["pattern"] = g["count"].apply(lambda c: "/" if c > 1 else "")

# 2) Tracer la timeline agr√©g√©e, color√©e par Cat√©gorie
import plotly.express as px
fig = px.timeline(
    g,
    x_start="D√©but",
    x_end="Fin",
    y="Utilisateur",
    color="Cat√©gorie",
    hover_data={"hover": True, "D√©but": False, "Fin": False, "Utilisateur": False, "Cat√©gorie": False},
    custom_data=["hover", "count"],
)
# inverser l'axe Y (meilleure lecture)
fig.update_yaxes(autorange="reversed")

# Appliquer le motif (bandes) seulement quand count>1
fig.update_traces(
    hovertemplate="%{customdata[0]}<extra></extra>",
    marker_line_width=0.5,
    marker_line_color="rgba(0,0,0,0.15)",
    selector=dict(type="bar")  # timeline = bar horizontale
)
# IMPORTANT : pattern par point
for trace in fig.data:
    # Pour chaque trace (cat√©gorie), on r√©cup√®re les indices du sous-ensemble dans g
    # Plotly ne donne pas l'index facilement, on reconstruit un array de patterns
    # bas√© sur l‚Äôordre d‚Äôapparition des points (m√™me ordre que g filtr√© par Cat√©gorie)
    cat_name = trace.name
    mask = (g["Cat√©gorie"] == cat_name)
    patterns = g.loc[mask, "pattern"].tolist()
    # Si la cat√©gorie n'est pas "Mixte" et a moins d'√©l√©ments, on ajuste
    if len(patterns) != len(trace.x):
        # fallback: ne pas crasher, r√©p√©ter / tronquer
        from itertools import islice, cycle
        patterns = list(islice(cycle(patterns or [""]), 0, len(trace.x)))
    trace.marker.pattern = dict(shape=patterns, fgopacity=0.35, solidity=0.4)

fig.update_layout(
    height=520,
    margin=dict(l=20, r=20, t=30, b=20),
    legend_title_text="Cat√©gorie (Mixte = plusieurs cat√©gories le m√™me jour)",
    xaxis_title="Date",
    yaxis_title="Utilisateur"
)
st.plotly_chart(fig, use_container_width=True)
# ---------- Aper√ßu & Export des justificatifs (par jour + utilisateur) ----------
with st.expander("üìé Justificatifs (aper√ßu + export par jour)"):
    if 'g' in locals() and not g.empty:
        # S√©lecteurs jour/utilisateur bas√©s sur les points visibles
        jours_dispos = sorted(g["Jour"].dt.strftime("%Y-%m-%d").unique().tolist())
        users_dispos = sorted(g["Utilisateur"].unique().tolist())
        sel_day = st.selectbox("Jour", jours_dispos) if jours_dispos else None
        sel_user = st.selectbox("Utilisateur", users_dispos) if users_dispos else None

        if sel_day and sel_user:
            day_dt = pd.to_datetime(sel_day).date()
            # Sous-ensemble des lignes (cal_f) de ce jour + utilisateur
            sub = cal_f[
                (cal_f["Utilisateur"] == sel_user) &
                (cal_f["Date"].dt.date == day_dt)
            ].copy().sort_values("Date")

            if sub.empty:
                st.info("Aucune note ce jour pour cet utilisateur.")
            else:
                st.markdown(f"**{sel_user} ‚Äî {sel_day}**  \n_Missions:_ {', '.join(sorted(set(sub['MissionLib'].astype(str))))}")
                st.divider()

                # Pr√©parer un ZIP global "jour" si des justificatifs existent
                import zipfile
                from io import BytesIO
                zip_buffer = BytesIO()
                zip_count = 0

                for i, r in sub.iterrows():
                    ref = str(r.get("R√©f√©rence", "")).strip()
                    cat = str(r.get("Cat√©gorie", "")).strip()
                    nom_dep = str(r.get("Nom de la d√©pense", "")).strip()
                    montant = ""
                    if "TTC (EUR)" in sub.columns and pd.notna(r.get("TTC (EUR)")):
                        montant = f"{r['TTC (EUR)']:.2f} EUR"
                    elif "TTC" in sub.columns and pd.notna(r.get("TTC")):
                        montant = f"{r['TTC']}"

                    st.markdown(f"**{cat}** ¬∑ _{nom_dep}_  ‚Äî  {montant or '‚Äî'}  \nR√©f : `{ref}`")

                    files = receipts_index.get(ref, [])
                    if not files:
                        st.caption("Aucun justificatif trouv√© pour cette r√©f√©rence (ZIP non fourni ou fichier absent).")
                    else:
                        # Preview + download par fichier
                        cols = st.columns(min(3, len(files)))
                        for j, (fname, data) in enumerate(files):
                            with cols[j % len(cols)]:
                                ext = os.path.splitext(fname)[1].lower()
                                st.write(fname)
                                if ext in [".png", ".jpg", ".jpeg", ".webp"]:
                                    st.image(data, use_column_width=True)
                                # Bouton de t√©l√©chargement individuel
                                st.download_button(
                                    "T√©l√©charger",
                                    data=data,
                                    file_name=fname,
                                    mime="application/octet-stream",
                                    key=f"dl_{ref}_{j}"
                                )
                        # Ajout au ZIP global du jour
                        with zipfile.ZipFile(zip_buffer, "a", zipfile.ZIP_DEFLATED) as zf:
                            for fname, data in files:
                                # Chemin lisible dans le ZIP jour
                                zf.writestr(f"{ref}/{fname}", data)
                                zip_count += 1

                    st.markdown("---")

                # Bouton d‚Äôexport ZIP du jour
                if zip_count > 0:
                    zip_buffer.seek(0)
                    st.download_button(
                        "üì¶ T√©l√©charger tous les justificatifs de ce jour (ZIP)",
                        data=zip_buffer.getvalue(),
                        file_name=f"justificatifs_{sel_user}_{sel_day}.zip",
                        mime="application/zip",
                        key=f"zip_day_{sel_user}_{sel_day}"
                    )
                else:
                    st.caption("Aucun justificatif √† exporter pour cette s√©lection.")
    else:
        st.info("Le graphique doit contenir des donn√©es pour activer cette section.")

# 3) D√©tails uniquement pour les jours multi-notes
with st.expander("üîé D√©tails des jours avec plusieurs notes de frais"):
    multi = g[g["count"] > 1].sort_values(["Utilisateur","Jour"])
    if multi.empty:
        st.write("Aucun jour ne contient plusieurs notes de frais.")
    else:
        for _, row in multi.iterrows():
            u, d = row["Utilisateur"], row["Jour"]
            sub = tmp[(tmp["Utilisateur"]==u) & (tmp["Date"].dt.floor("D")==d)].copy()
            sub = sub.sort_values("Date")
            st.markdown(f"**{u} ‚Äî {d.strftime('%Y-%m-%d')}**  \n_Cat√©gories:_ {', '.join(sorted(set(sub['Cat√©gorie'])))}  \n_Nombre de notes:_ {len(sub)}")
            for _, r in sub.iterrows():
                montant = ""
                if "TTC (EUR)" in r and pd.notna(r["TTC (EUR)"]):
                    montant = f" ‚Äî {r['TTC (EUR)']:.2f} EUR"
                elif "TTC" in r and pd.notna(r["TTC"]):
                    montant = f" ‚Äî {r['TTC']}"
                st.write(f"- **{r['Cat√©gorie']}** ¬∑ {r['Nom de la d√©pense']}{montant}")
# Liste par jour (utile fa√ßon ‚Äúagenda‚Äù)
with st.expander("üóíÔ∏è Vue 'agenda' (liste par jour)"):
    agenda = (
        cal_f.sort_values("Date")
            .assign(Jour=lambda d: d["Date"].dt.strftime("%Y-%m-%d"))
            .groupby("Jour")
    )
    for day, g in agenda:
        st.markdown(f"**{day}**")
        for _, r in g.iterrows():
            montant = ""
            if "TTC (EUR)" in r and pd.notna(r["TTC (EUR)"]):
                montant = f" ‚Äî {r['TTC (EUR)']:.2f} EUR"
            st.write(
                f"- {r['Utilisateur']} ¬∑ _{r['Cat√©gorie']}_ ¬∑ "
                f"**{r['Nom de la d√©pense']}**{montant}"
            )
st.markdown("""
<div style="text-align: center; color: #666; padding: 2rem; margin-top: 3rem; background: linear-gradient(to right, #f8f9fa, #e9ecef); border-radius: 10px;">
    <p style="font-size: 1.2rem; margin-bottom: 0.5rem;">
            <strong>ADVENT+ - Expensya Justificatifs Manager</strong>
    </p>
    <p style="margin-bottom: 0.5rem;"> Internal Distribution Analysis & Automation Platform - v1.0</p>
    <p style="font-size: 0.9rem; margin-top: 0.8rem;">
        üîπ G√©n√©ration automatique de dossiers missions ‚Ä¢ <br>
        üîπ Gestion s√©curis√©e des justificatifs clients ‚Ä¢ <br>
        üîπ Int√©gration OneDrive & Expensya ‚Ä¢ <br>
        üîπ Contr√¥le utilisateur par authentification
    </p>
    <p style="font-size: 0.8rem; margin-top: 1rem;">
        <strong>üîí Confidentialit√© :</strong> Usage interne r√©serv√© √† <b>ADVENT+</b> ‚Ä¢ 
        Acc√®s restreint par login/mot de passe
    </p>
    <p style="font-size: 0.8rem; margin-top: 1rem;">
        <a href="#" style="color: #2E86C1; text-decoration:none;">üìò Documentation</a> |
        <a href="#" style="color: #2E86C1; text-decoration:none;">üîê Politique de confidentialit√©</a>
    </p>
</div>
""", unsafe_allow_html=True)